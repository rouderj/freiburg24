---
title: "Hierarhcical Models"
author: Jeff Rouder
date:  May, 2024

output:
  beamer_presentation:
    theme: "metropolis"
    fonttheme: "structurebold"
    fig_caption: false
    incremental: false
    
header-includes   :
   - \usepackage{bm}
   - \usepackage{pcl}
   - \usepackage{amsmath}    
---

```{r,echo=F,eval=T,warning=F,message=F}
knitr::opts_chunk$set(echo = FALSE,message=FALSE, warning=FALSE)
set.seed(1256)
library(MCMCpack)
```

##


1. We wish to estimate how fast each of you are to react to a tone.  When you hear a tone, hit a button.  Pretty boring.

2. Let's assume each person has a *true score.*  This is your speed in the limit of infinitely many trials.  

3. If you know the $i$th person's true score, denoted $\mu_i$, then RT on the $j$th trial, denoted $Y_{ij}$, is distributed as
\[
Y_{ij}|\mu_i\sim \mbox{N}(\mu_i,.15^2),
\]
where $Y$ is measured in seconds.

4. Suppose we sample people from a population.  Then it is reasonable to think each person's true score is also distributed
\[
\mu_i \sim \mbox{N}(.5,.1^2)
\]

## Consider This

- We wish to estimate $\mu_i$.

- Some ppl recommend sample mean: (J trials)
\[
\hat{\mu_i} = \bar{y}_i=\sum_{j=1}^J y_{ij}/J
\]

- Other ppl recommend the median:
Order values, pick middle one.

## Jeff's Estimator

- I propose the following *regularized* estimator:
  + $\bar{y}_i$ is usual sample mean
  + $s^2_i$ is usual sample variance
  + $s^2 = \sum_{i=1}^I s^2_i / I$
  + $\bar{y}$ is grand mean; mean of $\bar{y}_i$:
    + $\bar{y}= \sum_{i=1}^I \bar{y}_i/I = \sum_{ij} y_{ij}/IJ$ 
  + $s^2_{\bar{y}}$ is standard error squared; variance of $\bar{y}_i$
    + $s^2_{\bar{y}} = \sum_i (\bar{y}_i-\bar{y})^2/(I-1)$

\[ \hat{\mu}_i = vc,\] 
where
\[
\begin{aligned}
v&=\left(\frac{J}{s^2}+\frac{1}{s^2_{\bar{y}}}\right)^{-1}\\
c_i&=\left(\frac{J\bar{y}_i}{s^2}+\frac{\bar{y}}{s^2_{\bar{y}}}\right)
\end{aligned}
\]

## Jeff's Estimator

- Whacky
- Legitimate as it uses nothing but the data
- Which of the three is best

## Defining Best

- Generate ground truth $(\mu_1,\ldots,\mu_I)$
- Generate data $\bfY$
- Compute estimates $(\hat{\mu}_1,\ldots,\hat{\mu_I})$
- Compute estimation error: $e_i = \hat{\mu}_i -\mu_i$
- Compute RMS error: $\mbox{rmse} = \sqrt{\sum_i e^2_i/I}$
 
## Example


```{r}
I=10 #people
J=9 #trial
sub=rep(1:I,each=J)

makeTrue=function(I,m,sdPop) rnorm(I,m,sdPop)

makeDat=function(I,J,true,sdTrl) rnorm(I*J,true[sub],sdTrl)

est.mean=function(dat)
  tapply(dat,sub,mean)

est.median=function(dat)
  tapply(dat,sub,median)

est.jeff= function(dat){
  s2=mean(tapply(dat,sub,var))
  m=est.mean(dat)
  s2m=var(m)
  v=1/(J/s2+1/s2m)
  c=J*m/s2+mean(m)/s2m
  return(v*c)
}
  
rmse=function(est,true) sqrt(mean((est-true)^2))
```

```{r}
cycle=function(I,J,mPop,sdPop,sdTrl){
  true=makeTrue(I,mPop,sdPop)
  dat=makeDat(I,J,true,sdTrl)
  e1=est.mean(dat)
  e2=est.median(dat)
  e3=est.jeff(dat)
  out=1:3
  out[1]=rmse(e1,true)
  out[2]=rmse(e2,true)
  out[3]=rmse(e3,true)
  names(out)=c("Mean","Median","Jeff's")
  return(list(true=true,out=out,est=cbind(e1,e2,e3)))
}
```

```{r}
set.seed(123)
par(cex=1.5)
g=cycle(I,J,.5,.1,.15)
true=g$true
est=g$est
matplot(true,est,typ='p')
print(round(g$out,3))
```

## Do it 10,000 Times

```{r}
R=1000
par(cex=1.5)
val=matrix(nrow=R,ncol=3)
for (r in 1:R)
  val[r,]=cycle(I,J,.5,.1,.15)$out
plot(val[,1],val[,3],col=rgb(1,0,0,.1),pch=19,
     xlab="Error of Mean",ylab="Jeff's Error")
abline(0,1)
print(paste("Proportion of Jeff's Wins:",mean(val[,3]<val[,1])))
```

## How Did I Do That

My estimator was based on the fact that the data were hierarchical

- People sampled from a population
- Trials nested in people
- Two sources of variation



## Case 1

- Each person reads 10 nouns.
- How good of a reader is each person.

## True Values

- Let $\mu_i$ denote the true value for the $i$th person


## Data + Model
- Data, $Y_{ij}$, $j$ denotes replicate for $i$th person
- $Y_{ij} \sim \mbox{N}(\mu_i,\sigma^2)$

   
```{r}
set.seed(123)
I=20
J=10
sub=rep(1:I,each=J)
tMu=sample(seq(500,500+(I-1)*10,10),I)
tS2=200^2
y=round(rnorm(I*J,tMu[sub],sqrt(tS2)),1)
dat=data.frame(sub,y)
write.table(dat,file="hier1.dat",row.names = F, quote = F)
```

## Mean score per person

```{r}
par(cex=1.5)
ybar=tapply(y,sub,mean)
plot(1:I,ybar,ylab="Sample Mean (ms)",xlab="Participant Number",
     xlim=c(0,20),pch=19,col="red")
```

## Mean score per person (sorted)

```{r}
par(cex=1.5)
ybar=tapply(y,sub,mean)
o=order(ybar)
plot(1:I,ybar[o],ylab="Sample Mean (ms)",xlab="Participant Number",
     xlim=c(0,20),pch=19,col="red")
```

## Sample Mean vs. True Mean
```{r}
par(cex=1.5)
plot(tMu,ybar,ylab="Sample Mean (ms)",xlab="True Mean",pch=19,col="darkgreen")
```

## Non-Hierarchical Bayes Model

\[
\begin{aligned}
Y_{ij} &\sim \mbox{N}(\mu_i,\sigma^2)\\
\mu_i &\sim \mbox{N}(a,b)\\
\sigma^2 &\sim \mbox{IG}(q,s) 
\end{aligned}
\]

- $a=600$
- $b=400^2$

## Non-Hierarchical Bayes Model

Conditional Posteriors via Bayes Rule:

\[ \begin{aligned}
\mu_i &\sim \mbox{N}(c_iv,v)\\
v &=\left(\frac{J}{\sigma^2}+\frac{1}{b}\right)\\
c_i &=\left(\frac{J\bar{Y}_i}{\sigma^2}+\frac{a}{b}\right)
\end{aligned}
\]

\[
\sigma^2 \sim \mbox{IG}(q+IJ/2,r+\mbox{SSE}/2)
\]

## Plan of Chain

- Sample all $\mu$'s given $\sigma^2$
- Sample $\sigma^2$ given all$\mu$'s.
- Repeat

## Results

```{r}
M=2000

a=600
b=400^2
q=2
s=200^2

mu=matrix(nrow=M,ncol=I)
s2=1:M
mu[1,]=ybar
s2[1]=200^2

for (m in 2:M){
  v=1/(J/s2[m-1]+1/b)
  c=J*ybar/s2[m-1]+a/b
  mu[m,]=rnorm(I,c*v,sqrt(v))
  scale=s+sum((y-mu[m,sub])^2)/2
  s2[m]=rinvgamma(1,q+I*J/2,scale=scale)
}

nonhier=apply(mu,2,mean)

par(cex=1.5)
plot(ybar,nonhier,ylab="Non-Hierarchical Estimate (ms)",xlab="Sample Mean",pch=19,col='darkblue')
abline(0,1)
```

## Hierarchical 

These people can be treated as fixed or random.

- Fixed.  I am interested in John Q. Doe as a unique individual.  Whatever results I find cannot be generalized.  
- Random.  I sample John Q. Doe from a population and would like to generalize to the population as well.

We treated each person as fixed in the previous case.

## Hierarchical

People as random effects

## Hierarchical

\[
\begin{aligned}
Y_{ij} &\sim \mbox{N}(\mu_i,\sigma^2)\\
\mu_i &\sim \mbox{N}(\eta,\delta)\\
\sigma^2 &\sim \mbox{IG}(q_1,r_1)\\ 
\eta & \sim \mbox{N}(a,b)\\
\delta & \sim \mbox{IG}(q_2,r_2)
\end{aligned}
\]

## Hierarchical

- Stage 1: Sample people from a population model
\[
\mu_i \sim \mbox{N}(\eta,\delta)
\]

- Stage 2: Sample observations from each person.

\[
Y_{ij} \sim \mbox{N}(\mu_i,\sigma^2)
\]

## Hierarchical

We all act as prior for each other.

## Hierarchical
Conditional Posteriors

\[ \begin{aligned}
\mu_i &\sim \mbox{N}(c_iv,v)\\
v &=\left(\frac{J}{\sigma^2}+\frac{1}{\delta}\right)\\
c_i &=\left(\frac{J\bar{Y}_i}{\sigma^2}+\frac{\eta}{\delta}\right)
\end{aligned}
\]

\[
\sigma^2 \sim \mbox{IG}(q_1+IJ/2,\;r_1+\sum_{ij}(Y_{ij}-\mu_i)^2/2)
\]

## Hierarchical
Conditional Posteriors
\[
\begin{aligned}
\eta &\sim \mbox{N}(c_0v_0,v_0)\\
v_0 &=\left(\frac{I}{\delta}+\frac{1}{b}\right)\\
c_0 &=\left(\frac{I\bar{\mu}}{\delta}+\frac{a}{b}\right)
\end{aligned}
\]

\[
\delta \sim \mbox{IG}(q_2+I/2,\;r_2+\sum_{i}(\mu_{i}-\eta)^2/2)
\]

## Hierarchical Results

```{r}
M=2000

a=600
b=400^2
q1=2
s1=200^2
q2=2
s2=50^2


mu=matrix(nrow=M,ncol=I)
s2=1:M
eta=1:M
delta=1:M

mu[1,]=ybar
s2[1]=200^2
eta[1]=mean(mu[1,])
delta=50^2

for (m in 2:M){
  v=1/(J/s2[m-1]+1/delta[m-1])
  c=J*ybar/s2[m-1]+eta[m-1]/delta[m-1]
  mu[m,]=rnorm(I,c*v,sqrt(v))
  scale=s1+sum((y-mu[m,sub])^2)/2
  s2[m]=rinvgamma(1,q1+I*J/2,scale=scale)
  v=1/(I/delta[m-1]+1/b)
  c=I*mean(mu[m,])/delta[m-1]+a/b
  eta[m]=rnorm(1,v*c,sqrt(v))
  scale=s2+sum((mu[m,]-eta[m])^2)/2
  delta[m]=rinvgamma(1,q2+I/2,scale=scale)  
}

hier=apply(mu,2,mean)

par(cex=1.5)
plot(ybar,hier,ylab="Hierarchical Estimate (ms)",xlab="Sample Mean",pch=19,col='darkblue')
abline(0,1)
```


## Sorted by People
```{r}
par(cex=1.5)
ybar=tapply(y,sub,mean)
o=order(ybar)
plot(1:I,ybar[o],ylab="Estimates (ms)",
     xlab="Participant Number",
     xlim=c(0,20),pch=19,col="red")
lines(1:I,ybar[o],col='darkred')
lines(1:I,hier[o],col='darkblue')
points(1:I,hier[o],pch=19,col="blue")
legend(0,700,c("Non-Hier","Hier"),col=c("red","blue"),pch=19)
```

## Versus True Values

```{r}
par(cex=1.5)
plot(tMu,ybar,ylab="Estimate (ms)",xlab="True Mean",pch=19,col="red")
points(tMu,hier,pch=19,col="blue")
abline(0,1)
par(xpd=T)
legend(500,750,c("Non-Hier","Hier"),col=c("red","blue"),pch=19,bg="white")
par(xpd=F)
```

## JAGS

- I wrote a hierarchical model in jags in normJ (model 2)

- Go see if you can get out the parameter estimates, plot them, do they match.  






